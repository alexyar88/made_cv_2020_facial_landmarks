{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Соревнование Thousand Facial Landmarks по Computer Vision в MADE\n",
    "Студент: Алексей Ярошенко\n",
    "\n",
    "**Что сработало:**\n",
    "- Т.к. модели обучены на imagenet, взял нормировочные константы оттуда.\n",
    "-  Увеличил CROP_SIZE до 224, как в imagenet. К тому же, подумал, что чем выше разрешение, тем можно точнее попасть в нужный пиксель.\n",
    "- Увеличил размер трейна с 80 до 97%. Для адекватной валидации хватало 3% (11 000+ картинок), датасет  относительно большой.\n",
    "- Модели учились чутка нестабильно, по разному. Долго с этим возился. В конце концов, пришел к тому, что использовал sсheduler CosineAnnealingWarmRestarts, чтобы менять lr по синусоиде от максимума до нуля, каждый раз удваивая период после рестарта. С ним модели начали лучше и стабильнее сходиться. В статьях пишут, что с ним больше вероятность найти лучший локальный минимум. У меня работал лучше чем ReduceLROnPlateau.\n",
    "- Учил модели адамом, дообучал на SGD. Прочел где-то, попробовал так делать, и иногда получалось небольшое повышение метрики выжать. Хотя возможно, с SGD сеть медленнее училась и на маленьком размере батча просто не успевала переобучиться.\n",
    "- Делал рестарты. Т.е. если видел, что модель не сходится/переобучается и откатывался к последнему чекпойнту и менял что-то: оптимайзер, LR, перезапускал scheduler.\n",
    "- Добавил регуляризацию. Небольшой weight_decay делал модель устойчивее на самых последних этапах, когда сеточка начинает переобучаться. Скор на валидации от этого не рос, но на паблике это было в плюс.\n",
    "- Протестировал много предобученных моделей из torchvision. Лучше всего зашли densenet\n",
    "- Я понадеялся, что ошибки хотя бы на некоторых точках нормально распределены и если я наставлю несколько точек на плоскости, то центр будет лучше предсказывать точку. Скачал топ своих лучших сабмитов для разных архитектур/моделей, усреднил предсказания. К тому же, скорее всего, это сделало модель стабильнее и дало еще небольшой буст после конца соревнования, когда открылся private leaderboard. На паблике я за 2 часа до конца стал вторым, на привате снова выкинуло на 1-е место.\n",
    "- Усреднил топ сабмитов со взвешиванием: у лучшего скора больший вес.\n",
    "- Логировал результат трейна и теста каждой эпохи в телеграм, чтобы, если, к примеру случайно проснулся ночью, можно при необходимости сделать рестарт обучения с новыми параметрами. Из кода убрал, ибо он особого смысла не несет.\n",
    "\n",
    "**Что не помогло:**\n",
    "- Замораживать слои. Дообучать разные слои с разным lr. Дообучать по очереди. Быстрее становилось, лучше - нет. Нужно, к тому же, за этим следить.\n",
    "- Подмешивать какой-то еще лосс (к примеру smooth_l1_loss). Наверное, это логично, ибо не представляю, что может быть лучше оптимизации MSE, когда у нас целевая метрика - MSE. Только если как своеобразный регуляризатор, наверное.\n",
    "- Простые аугментации вроде контраста, насыщенности и т.д. К тому же, данных достаточно, а если накинуть пару аугментаций, все совсем долго считается.\n",
    "- Поднимать разрешение выше 224. Больших картинок не очень много, а учится сеть неприлично дольше. Батчи становятся все меньше, ибо памяти не хватает. Возможно, и дало бы скор лучше, но я бы его просто не дождался.\n",
    "\n",
    "**Чего не делал:**\n",
    "- Не очень удобных в написании аугментаций к примеру, с поворотом. \n",
    "- Не чистил выбросы. Наверное, стоило бы. Но я подумал, что раз выбросы есть и в тесте, и трейне, пускай модель хоть что-то из них выучит. Но тут без понятия.\n",
    "- Не использовал сторонних библиотек и архитектур кроме torchvision.models.\n",
    "\n",
    "![Submit screeshot](submit_screenshot.png)\n",
    "\n",
    "P.S.: ансамблирование с описанием модели для каждого сабмита, который я использовал в ансамбле, в самом низу ноутбука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import tqdm\n",
    "from torch.nn import functional as fnn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hack_utils import NUM_PTS, CROP_SIZE\n",
    "from hack_utils import ScaleMinSideToSize, CropCenter, TransformByKeys\n",
    "from hack_utils import ThousandLandmarksDataset\n",
    "from hack_utils import restore_landmarks_batch, create_submission\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "MODEL_NAME = 'densenet169_anealing_b16_train097_size224_norm_imgnet'\n",
    "GPU = True\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "CROP_SIZE = 224\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for batch in tqdm.tqdm(loader, total=len(loader), desc=\"training...\"):\n",
    "        images = batch[\"image\"].to(device)  # B x 3 x CROP_SIZE x CROP_SIZE\n",
    "        landmarks = batch[\"landmarks\"]  # B x (2 * NUM_PTS)\n",
    "\n",
    "        pred_landmarks = model(images).cpu()  # B x (2 * NUM_PTS)\n",
    "        loss = loss_fn(pred_landmarks, landmarks, reduction=\"mean\")        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "# для CosineAnnealingWarmRestarts\n",
    "def train_anealing(model, loader, loss_fn, optimizer, scheduler, epoch, device):\n",
    "    model.train()\n",
    "    iters = len(loader)\n",
    "    i = 0\n",
    "    train_loss = []\n",
    "    for batch in tqdm.tqdm(loader, total=len(loader), desc=\"training...\", position=0, leave=True):\n",
    "        images = batch[\"image\"].to(device)  # B x 3 x CROP_SIZE x CROP_SIZE\n",
    "        landmarks = batch[\"landmarks\"]  # B x (2 * NUM_PTS)\n",
    "\n",
    "        pred_landmarks = model(images).cpu()  # B x (2 * NUM_PTS)\n",
    "        loss = loss_fn(pred_landmarks, landmarks, reduction=\"mean\")\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch + i / iters)\n",
    "        i += 1\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def validate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    for batch in tqdm.tqdm(loader, total=len(loader), desc=\"validation...\"):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        landmarks = batch[\"landmarks\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_landmarks = model(images).cpu()\n",
    "        loss = loss_fn(pred_landmarks, landmarks, reduction=\"mean\")\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = np.zeros((len(loader.dataset), NUM_PTS, 2))\n",
    "    for i, batch in enumerate(tqdm.tqdm(loader, total=len(loader), desc=\"test prediction...\")):\n",
    "        images = batch[\"image\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_landmarks = model(images).cpu()\n",
    "        pred_landmarks = pred_landmarks.numpy().reshape((len(pred_landmarks), NUM_PTS, 2))  # B x NUM_PTS x 2\n",
    "\n",
    "        fs = batch[\"scale_coef\"].numpy()  # B\n",
    "        margins_x = batch[\"crop_margin_x\"].numpy()  # B\n",
    "        margins_y = batch[\"crop_margin_y\"].numpy()  # B\n",
    "        prediction = restore_landmarks_batch(pred_landmarks, fs, margins_x, margins_y)  # B x NUM_PTS x 2\n",
    "        predictions[i * loader.batch_size: (i + 1) * loader.batch_size] = prediction\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "382112it [06:07, 1040.19it/s]\n",
      "393931it [00:12, 31934.70it/s] \n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    ScaleMinSideToSize((CROP_SIZE, CROP_SIZE)),\n",
    "    CropCenter(CROP_SIZE),\n",
    "    TransformByKeys(transforms.ToPILImage(), (\"image\",)),\n",
    "    TransformByKeys(transforms.ToTensor(), (\"image\",)),\n",
    "    TransformByKeys(transforms.Normalize(mean=NORM_MEAN, std=NORM_STD), (\"image\",)),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    ScaleMinSideToSize((CROP_SIZE, CROP_SIZE)),\n",
    "    CropCenter(CROP_SIZE),\n",
    "    TransformByKeys(transforms.ToPILImage(), (\"image\",)),\n",
    "    TransformByKeys(transforms.ToTensor(), (\"image\",)),\n",
    "    TransformByKeys(transforms.Normalize(mean=NORM_MEAN, std=NORM_STD), (\"image\",)),\n",
    "])\n",
    "\n",
    "train_dataset = ThousandLandmarksDataset(os.path.join(DATA_PATH, 'train'), train_transforms, split=\"train\")\n",
    "val_dataset = ThousandLandmarksDataset(os.path.join(DATA_PATH, 'train'), test_transforms, split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=7, pin_memory=True,\n",
    "                                   shuffle=True, drop_last=True)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=7, pin_memory=True,\n",
    "                                 shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda: 0\") if GPU else torch.device(\"cpu\")\n",
    "model = models.densenet169(pretrained=True)\n",
    "\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 2 * NUM_PTS, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "# Один из оптимайзеров закомментирован, т.к. часто использовал оба. Сначала Adam, потом SGD\n",
    "# optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum=0.9, nesterov=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, amsgrad=True, weight_decay=0.00001)\n",
    "\n",
    "# Меняем LR от максимума до нуля по синусоиде за 1 эпоху. \n",
    "# Потом повторяем, каждый раз с периодом в 2 раза больше\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=len(train_dataloader), \n",
    "    T_mult=2\n",
    ")\n",
    "loss_fn = fnn.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для рестарта, чтобы дальше обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"{MODEL_NAME}_best.pth\", \"rb\") as fp:\n",
    "#     best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "#     model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation...: 100%|██████████| 739/739 [00:56<00:00, 13.10it/s]\n",
      "training...:   0%|          | 0/23881 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start val loss: 1.36e+04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 23881/23881 [1:16:47<00:00,  5.18it/s]\n",
      "validation...: 100%|██████████| 739/739 [00:56<00:00, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 0:\ttrain loss: 44.95\tval loss: 7.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = validate(model, val_dataloader, loss_fn, device=device)\n",
    "print(\"Start val loss: {:5.4}\".format(best_val_loss))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_anealing(model, train_dataloader, loss_fn, optimizer, scheduler, epoch, device=device)\n",
    "    val_loss = validate(model, val_dataloader, loss_fn, device=device)\n",
    "    print(\"Epoch #{:2}:\\ttrain loss: {:5.4}\\tval loss: {:5.4}\".format(epoch, train_loss, val_loss))\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        with open(f\"{MODEL_NAME}_best.pth\", \"wb\") as fp:\n",
    "            torch.save(model.state_dict(), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делаем сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99820it [00:00, 765764.15it/s]\n",
      "test prediction...: 100%|██████████| 6239/6239 [07:57<00:00, 13.08it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ThousandLandmarksDataset(os.path.join(DATA_PATH, 'test'), test_transforms, split=\"test\")\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=8, pin_memory=True,\n",
    "                                  shuffle=False, drop_last=False)\n",
    "\n",
    "with open(f\"{MODEL_NAME}_best.pth\", \"rb\") as fp:\n",
    "    best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "    model.load_state_dict(best_state_dict)\n",
    "\n",
    "test_predictions = predict(model, test_dataloader, device)\n",
    "with open(f\"{MODEL_NAME}_test_predictions.pkl\", \"wb\") as fp:\n",
    "    pickle.dump({\"image_names\": test_dataset.image_names,\n",
    "                 \"landmarks\": test_predictions}, fp)\n",
    "\n",
    "\n",
    "del test_dataset, test_dataloader\n",
    "gc.collect()\n",
    "\n",
    "create_submission(DATA_PATH, test_predictions, f\"{MODEL_NAME}_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ансамблирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл сабмита на kaggle: densenet201_anealing_b16_train095_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: densenet201\n",
    "# Размер батча: 16\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Размер обучающей выборки: 0.95\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.04\n",
    "df_1 = pd.read_csv('submit_804.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: resnext101_32x8d_anealing_b16_train095_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: resnext101_32x8d\n",
    "# Размер батча: 16\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Размер обучающей выборки: 0.95\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.14\n",
    "df_2 = pd.read_csv('submit_814.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: resnext50_32x4d_anealing_b32_train097_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: resnext50_32x4d\n",
    "# Размер батча: 32\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Размер обучающей выборки: 0.97\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.22\n",
    "df_3 = pd.read_csv('submit_822.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: resnet34_2_anealing_b64_train097_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: resnet34\n",
    "# Размер батча: 64\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Размер обучающей выборки: 0.97\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.32\n",
    "df_4 = pd.read_csv('submit_832.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: densenet169_anealing_b16_train097_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: densenet169\n",
    "# Размер батча: 16\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Размер обучающей выборки: 0.97\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.33\n",
    "df_5 = pd.read_csv('submit_833.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: densenet169_pipeline5_anealing_b32_train09_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: densenet169\n",
    "# Размер батча: 32\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Размер обучающей выборки: 0.9\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.34\n",
    "df_6 = pd.read_csv('submit_834.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: resnet34_sgd_annealing_b32_lr1e3_train095_size256_norm_imgnet_submit.csv\n",
    "# Архитектура: resnet34\n",
    "# Размер батча: 32\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Learning rate: 1e-3\n",
    "# Размер обучающей выборки: 0.95\n",
    "# Размер картинки: 256х256\n",
    "# Результат на паблике: 8.47\n",
    "df_7 = pd.read_csv('submit_847.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: resnext50_32x4d_anealing_b32_train097_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: resnext50_32x4d\n",
    "# Размер батча: 32\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Размер обучающей выборки: 0.97\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.49\n",
    "df_8 = pd.read_csv('submit_849.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: densenet121_anealing_b32_train097_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: densenet121\n",
    "# Размер батча: 32\n",
    "# Размер обучающей выборки: 0.97\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.51\n",
    "df_9 = pd.read_csv('submit_851.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: resnet50_3_nofreeze_steps_b128_lr3e4_train09_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: resnet50\n",
    "# Размер батча: 128\n",
    "# Размер обучающей выборки: 0.9\n",
    "# Размер картинки: 224х224\n",
    "# Обучалась по частям: сначала классификатом, потом по шагам размораживались слои и снижался Learning rate\n",
    "# Результат на паблике: 8.57\n",
    "df_10 = pd.read_csv('submit_857.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: densenet121_anealing_b32_lr1e3_train09_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: densenet121\n",
    "# Размер батча: 32\n",
    "# Scheduler: CosineAnnealingWarmRestarts (T_mult=2)\n",
    "# Learning rate: 1e-3\n",
    "# Размер обучающей выборки: 0.9\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.59\n",
    "df_11 = pd.read_csv('submit_859.csv')\n",
    "\n",
    "# Файл сабмита на kaggle: resnext50_32x4d_b32_lr3e4_train09_size224_norm_imgnet_submit.csv\n",
    "# Архитектура: resnext50_32x4d\n",
    "# Размер батча: 32\n",
    "# Learning rate: 3e-4\n",
    "# Размер обучающей выборки: 0.9\n",
    "# Размер картинки: 224х224\n",
    "# Результат на паблике: 8.74\n",
    "df_12 = pd.read_csv('submit_874.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10, df_11, df_12]\n",
    "\n",
    "# Перевзвесим сабмиты, чтобы лучшие сабмиты получили больший вес\n",
    "w = softmax(np.arange(len(dfs) + 1, 1, -1) / 10)\n",
    "\n",
    "df_result = dfs[0].copy()\n",
    "df_result.iloc[:, 1:] = df_result.iloc[:, 1:] * w[0]\n",
    "for i, df in enumerate(dfs[1:]):\n",
    "    df_result.iloc[:, 1:] += df.iloc[:, 1:] * w[i + 1]\n",
    "    \n",
    "df_result.iloc[:, 1:] = df_result.iloc[:, 1:].round().astype(int)\n",
    "\n",
    "df_result.to_csv('submit_ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
